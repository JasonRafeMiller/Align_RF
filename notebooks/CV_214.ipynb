{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG-tGRnlFLA3"
      },
      "source": [
        "# Cross Validation\n",
        "Random Forest.\n",
        "\n",
        "Brassica, hisat, genomes.\n",
        "\n",
        "Stats from Sorted.bam files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RmwUsVLFLA6",
        "outputId": "fd8bb30c-8a56-477c-a4ca-de09c72500ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-13 22:31:32.385038\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlzN9OdsFWEU",
        "outputId": "315eea4d-64e4-4038-8f44-8a1f474da38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Running on CoLab\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "dt='float32'\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(42) # supposedly leads to reproducible results\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print('Running on CoLab')\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATA_DIR=PATH+'My Drive/data/IRP2/Brassica/HiSat/'  # must end in \"/\"\n",
        "    MODEL_DIR=PATH+'My Drive/data/IRP2/Models/'  # must end in \"/\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print('Running on Mac')\n",
        "    DATA_DIR=\"Brassica/HiSat/\"\n",
        "    MODEL_DIR=\"Models/\"\n",
        "SAVE_MODEL_FILENAME = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIAT2G5DYwvS",
        "outputId": "46228630-1cae-4940-af94-c9f4e967ea29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "print('Python',python_version())\n",
        "import random\n",
        "import numpy as np\n",
        "np.random.seed(42) # supposedly sets scikit-learn\n",
        "import pandas as pd  # for plotting\n",
        "import time # sleep function\n",
        "from os.path import isfile\n",
        "import gzip\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn   # pip install --upgrade scikit-learn\n",
        "print('sklearn',sklearn.__version__)\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "EPOCHS=150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtqdpJOxFLBA"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkpVKdMFLA-",
        "outputId": "81e2961f-a3e4-45fc-a0bb-24d1f008dceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data directory: /content/drive/My Drive/data/IRP2/Brassica/HiSat/\n",
            "Data file 0 unfiltered.rapa_read_stats.csv.gz\n",
            "Data file 1 unfiltered.oleracea_read_stats.csv.gz\n",
            "Input lines for training: 1000000\n"
          ]
        }
      ],
      "source": [
        "MAX_LINES_TO_LOAD =    1000000 # training - 1M lines requires 2GB RAM\n",
        "#MAX_LINES_TO_LOAD =    10000 # use this for debugging\n",
        "\n",
        "VALID_PORTION = 0.20\n",
        "\n",
        "DATA_FILE_0 = 'unfiltered.rapa_read_stats.csv.gz'\n",
        "DATA_FILE_1 = 'unfiltered.oleracea_read_stats.csv.gz'\n",
        "\n",
        "print('Data directory: %s'%DATA_DIR)\n",
        "print('Data file 0 %s'%DATA_FILE_0)\n",
        "print('Data file 1 %s'%DATA_FILE_1)\n",
        "print('Input lines for training: %d'%MAX_LINES_TO_LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUBLdpVEVQ3I",
        "outputId": "33f71450-325e-4799-fac4-b59dd8e4692d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total feature names:  53\n",
            "0 P1 R1 AS\n",
            "1 P1 R1 ED\n",
            "2 P1 R1 MM\n",
            "3 P1 R1 HQMM\n",
            "4 P1 R1 GO\n",
            "5 P1 R1 GE\n",
            "6 P1 R1 INS\n",
            "7 P1 R1 DELS\n",
            "8 P1 R1 HQINS\n",
            "9 P1 R1 HQDEL\n",
            "10 P1 R2 AS\n",
            "11 P1 R2 ED\n",
            "12 P1 R2 MM\n",
            "13 P1 R2 HQMM\n",
            "14 P1 R2 GO\n",
            "15 P1 R2 GE\n",
            "16 P1 R2 INS\n",
            "17 P1 R2 DELS\n",
            "18 P1 R2 HQINS\n",
            "19 P1 R2 HQDEL\n",
            "20 P2 R1 AS\n",
            "21 P2 R1 ED\n",
            "22 P2 R1 MM\n",
            "23 P2 R1 HQMM\n",
            "24 P2 R1 GO\n",
            "25 P2 R1 GE\n",
            "26 P2 R1 INS\n",
            "27 P2 R1 DELS\n",
            "28 P2 R1 HQINS\n",
            "29 P2 R1 HQDEL\n",
            "30 P2 R2 AS\n",
            "31 P2 R2 ED\n",
            "32 P2 R2 MM\n",
            "33 P2 R2 HQMM\n",
            "34 P2 R2 GO\n",
            "35 P2 R2 GE\n",
            "36 P2 R2 INS\n",
            "37 P2 R2 DELS\n",
            "38 P2 R2 HQINS\n",
            "39 P2 R2 HQDEL\n",
            "40 Span diff\n",
            "41 AS diff\n",
            "42 ED diff\n",
            "43 MAT diff\n",
            "44 MM diff\n",
            "45 HQMM diff\n",
            "46 GO diff\n",
            "47 GE diff\n",
            "48 INS diff\n",
            "49 DELS diff\n",
            "50 HQINS diff\n",
            "51 HQDEL diff\n",
            "52 PARENT\n"
          ]
        }
      ],
      "source": [
        "# P1 parent 1\n",
        "# R1 read 1\n",
        "# PS primary or secondary\n",
        "# AS bowtie alignment score (0 is best)\n",
        "# ED edit distance\n",
        "# MM mismatch count\n",
        "# GO gap open count\n",
        "# GE gap extend count\n",
        "feature_names = [\n",
        "    'P1 R1 AS',\n",
        "    'P1 R1 ED',\n",
        "    ##'P1 R1 MAT',\n",
        "    'P1 R1 MM',\n",
        "    'P1 R1 HQMM',\n",
        "    'P1 R1 GO',\n",
        "    'P1 R1 GE',\n",
        "    'P1 R1 INS',\n",
        "    'P1 R1 DELS',\n",
        "    'P1 R1 HQINS',\n",
        "    'P1 R1 HQDEL',\n",
        "    'P1 R2 AS',\n",
        "    'P1 R2 ED',\n",
        "    ##'P1 R2 MAT',\n",
        "    'P1 R2 MM',\n",
        "    'P1 R2 HQMM',\n",
        "    'P1 R2 GO',\n",
        "    'P1 R2 GE',\n",
        "    'P1 R2 INS',\n",
        "    'P1 R2 DELS',\n",
        "    'P1 R2 HQINS',\n",
        "    'P1 R2 HQDEL',\n",
        "    'P2 R1 AS',\n",
        "    'P2 R1 ED',\n",
        "    ##'P2 R1 MAT',\n",
        "    'P2 R1 MM',\n",
        "    'P2 R1 HQMM',\n",
        "    'P2 R1 GO',\n",
        "    'P2 R1 GE',\n",
        "    'P2 R1 INS',\n",
        "    'P2 R1 DELS',\n",
        "    'P2 R1 HQINS',\n",
        "    'P2 R1 HQDEL',\n",
        "    'P2 R2 AS',\n",
        "    'P2 R2 ED',\n",
        "    ##'P2 R2 MAT',\n",
        "    'P2 R2 MM',\n",
        "    'P2 R2 HQMM',\n",
        "    'P2 R2 GO',\n",
        "    'P2 R2 GE',\n",
        "    'P2 R2 INS',\n",
        "    'P2 R2 DELS',\n",
        "    'P2 R2 HQINS',\n",
        "    'P2 R2 HQDEL',\n",
        "    ##'R1 length',\n",
        "    ##'R2 length',\n",
        "    ##'P1 span',\n",
        "    ##'P2 span',\n",
        "    'Span diff',\n",
        "    'AS diff',\n",
        "    'ED diff',\n",
        "    'MAT diff',\n",
        "    'MM diff',\n",
        "    'HQMM diff',\n",
        "    'GO diff',\n",
        "    'GE diff',\n",
        "    'INS diff',\n",
        "    'DELS diff',\n",
        "    'HQINS diff',\n",
        "    'HQDEL diff',\n",
        "    'PARENT']\n",
        "print('Total feature names: ',len(feature_names))\n",
        "for i in range(len(feature_names)):\n",
        "    print(i,feature_names[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p35ehKV3Kq0z"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self,filepath1,filepath2,verbose=True):\n",
        "        self.files = [filepath1,filepath2]\n",
        "        self.alignments=[]\n",
        "        self.labels=[]\n",
        "        self.verbose = verbose\n",
        "        self.max_lines = None\n",
        "        self.ties = 0\n",
        "        self.predictions = []\n",
        "        self.num_features = 1\n",
        "\n",
        "    def set_num_features(self,count):\n",
        "        self.num_features = count\n",
        "\n",
        "    def set_max_lines(self,lines):\n",
        "        '''Limit the dataset size to fit in RAM.'''\n",
        "        self.max_lines = lines\n",
        "        if self.verbose:\n",
        "            print('Maximum lines to load per file: %d'%lines)\n",
        "\n",
        "    def _count_lines_(self):\n",
        "        '''Show number of lines per input file.'''\n",
        "        count0 = 0\n",
        "        with gzip.open (self.files[0],'rt') as handle0:\n",
        "            for row in handle0:\n",
        "                count0 += 1\n",
        "        count1 = 0\n",
        "        with gzip.open(self.files[1],'rt') as handle1:\n",
        "            for row in handle1:\n",
        "                count1 += 1\n",
        "        minimum = min(count0,count1)\n",
        "        if self.verbose:\n",
        "            print('File0 size: %d %s'%(count0,self.files[0]))\n",
        "            print('File1 size: %d %s'%(count1,self.files[1]))\n",
        "        return minimum\n",
        "\n",
        "    def _load_line_(self,row):\n",
        "        '''Load data structure from one line of CSV file.'''\n",
        "        line = row.strip()\n",
        "        fields = line.split(',')\n",
        "        ints = [0] * self.num_features\n",
        "        # These fields come straight from the input file.\n",
        "        # These fields are grouped by which read they describe.\n",
        "        # P1 R1 = Parent 1, Read 1\n",
        "        ints[0] = int(fields[0]) # P1 R1 AS\n",
        "        ints[1] = int(fields[1]) # P1 R1 ED\n",
        "        P1R1_MAT = int(fields[2]) # P1 R1 MAT\n",
        "        ints[2] = int(fields[3]) # P1 R1 MM\n",
        "        ints[3] = int(fields[4]) # P1 R1 HQMM\n",
        "        ints[4] = int(fields[5]) # P1 R1 GO\n",
        "        ints[5] = int(fields[6]) # P1 R1 GE\n",
        "        ints[6] = int(fields[7]) # P1 R1 INS\n",
        "        ints[7] = int(fields[8]) # P1 R1 DELS\n",
        "        ints[8] = int(fields[9]) # P1 R1 HQINS\n",
        "        ints[9] = int(fields[10]) # P1 R1 HQDEL\n",
        "        #  = Parent 1, Read 2\n",
        "        ints[10] = int(fields[11]) # P1 R2 AS\n",
        "        ints[11] = int(fields[12]) # P1 R2 ED\n",
        "        P1R2_MAT = int(fields[13]) # P1 R2 MAT\n",
        "        ints[12] = int(fields[14]) # P1 R2 MM\n",
        "        ints[13] = int(fields[15]) # P1 R2 HQMM\n",
        "        ints[14] = int(fields[16]) # P1 R2 GO\n",
        "        ints[15] = int(fields[17]) # P1 R2 GE\n",
        "        ints[16] = int(fields[18]) # P1 R2 INS\n",
        "        ints[17] = int(fields[19]) # P1 R2 DELS\n",
        "        ints[18] = int(fields[20]) # P1 R2 HQINS\n",
        "        ints[19] = int(fields[21]) # P1 R2 HQDEL\n",
        "        # P2 R1 = Parent 2, Read 1\n",
        "        ints[20] = int(fields[22]) # P2 R1 AS\n",
        "        ints[21] = int(fields[23]) # P2 R1 ED\n",
        "        P2R1_MAT = int(fields[24]) # P2 R1 MAT\n",
        "        ints[22] = int(fields[25]) # P2 R1 MM\n",
        "        ints[23] = int(fields[26]) # P2 R1 HQMM\n",
        "        ints[24] = int(fields[27]) # P2 R1 GO\n",
        "        ints[25] = int(fields[28]) # P2 R1 GE\n",
        "        ints[26] = int(fields[29]) # P2 R1 INS\n",
        "        ints[27] = int(fields[30]) # P2 R1 DELS\n",
        "        ints[28] = int(fields[31]) # P2 R1 HQINS\n",
        "        ints[29] = int(fields[32]) # P2 R1 HQDEL\n",
        "        # P2 R2 = Parent 2, Read 2\n",
        "        ints[30] = int(fields[33]) # P2 R2 AS\n",
        "        ints[31] = int(fields[34]) # P2 R2 ED\n",
        "        P2R2_MAT = int(fields[35]) # P2 R2 MAT\n",
        "        ints[32] = int(fields[36]) # P2 R2 MM\n",
        "        ints[33] = int(fields[37]) # P2 R2 HQMM\n",
        "        ints[34] = int(fields[38]) # P2 R2 GO\n",
        "        ints[35] = int(fields[39]) # P2 R2 GE\n",
        "        ints[36] = int(fields[40]) # P2 R2 INS\n",
        "        ints[37] = int(fields[41]) # P2 R2 DELS\n",
        "        ints[38] = int(fields[42]) # P2 R2 HQINS\n",
        "        ints[39] = int(fields[43]) # P2 R2 HQDEL\n",
        "        # Fields that come in twos\n",
        "        R1_LEN = int(fields[44]) # R1 length (of read)\n",
        "        R2_LEN = int(fields[45]) # R2 length (of read)\n",
        "        P1_SPAN = int(fields[46]) # P1 span (of mapped read pair)\n",
        "        P2_SPAN = int(fields[47]) # P2 span (of mapped read pair)\n",
        "        # Read-wise differences\n",
        "        ints[40] = P2_SPAN-P1_SPAN # P2-P1 span diff\n",
        "        ints[41] = (ints[33]+ints[22])-(ints[11]+ints[0]) # AS diff\n",
        "        ints[42] = (ints[34]+ints[23])-(ints[12]+ints[1]) # ED diff\n",
        "        ints[43] = (P2R1_MAT+P2R2_MAT)-(P1R1_MAT+P1R2_MAT) # MAT diff\n",
        "        ints[44] = (ints[36]+ints[25])-(ints[14]+ints[3]) # MM diff\n",
        "        ints[45] = (ints[37]+ints[26])-(ints[15]+ints[4]) # HQMM diff\n",
        "        ints[46] = (ints[38]+ints[27])-(ints[16]+ints[5]) # GO diff\n",
        "        ints[47] = (ints[39]+ints[28])-(ints[17]+ints[6]) # GE diff\n",
        "        ints[48] = (ints[40]+ints[29])-(ints[18]+ints[7]) # INS diff\n",
        "        ints[49] = (ints[41]+ints[30])-(ints[19]+ints[8]) # DELS diff\n",
        "        ints[50] = (ints[42]+ints[31])-(ints[20]+ints[9]) # HQINS diff\n",
        "        ints[51] = (ints[43]+ints[32])-(ints[21]+ints[10]) # HQDEL diff\n",
        "        # The feature-extraction program populated a field\n",
        "        # to indicate which parent had higher alignment score.\n",
        "        # Values were 0=same, 1=parent1, 2=parent2.\n",
        "        # We change the values to -1=parent1, 0=unknown, +1=parent2\n",
        "        parent_choice = int(fields[48])\n",
        "        if parent_choice == 1:\n",
        "            ints[52] = -1  # not parent 2\n",
        "        elif parent_choice == 2:\n",
        "            ints[52] = 1  # is parent 2\n",
        "        elif parent_choice == 0:\n",
        "            ints[52] = 0\n",
        "        else:\n",
        "            raise Exception('Unrecognized parent choice:'+str(parent_choice))\n",
        "        # For fair comparison, force aligner to choose.\n",
        "        # We change 1 to 0, 2 to 1, and 0 to 1 or 2 randomly.\n",
        "        # TO DO: faster alternative to list.append() ???\n",
        "        parent_choice = int(fields[48])\n",
        "        if parent_choice == 1:\n",
        "            self.predictions.append(0)  # not parent 2\n",
        "        elif parent_choice == 2:\n",
        "            self.predictions.append(1)  # is parent 2\n",
        "        else: # parent_choice == 0:\n",
        "            self.ties += 1\n",
        "            guess = random.randint(0,1)\n",
        "            self.predictions.append(guess)\n",
        "        # The transcript that this read pair aligned to.\n",
        "        # This is for pipelines that only process reads that map\n",
        "        # to same transcript in both parents and (filter the others).\n",
        "        # Pipelines that assign reads to parent, regardless of which gene,\n",
        "        # should ignore this value. (It only reflects first parent map anyway.)\n",
        "        transcript_id = fields[49] # TO DO: where to put this?\n",
        "        self.alignments.append(ints)\n",
        "\n",
        "    def count_ties(self):\n",
        "        return self.ties\n",
        "\n",
        "    def load_full_train_set(self):\n",
        "        '''Load full train set (to be used for train and valiation).\n",
        "           Use set_max_lines() to leave some data for the test set.'''\n",
        "        minimum = 0\n",
        "        train_size = self.max_lines\n",
        "        if self.verbose:\n",
        "            print('Trying to load %d lines per file...'%train_size)\n",
        "        try:\n",
        "            handle0 = gzip.open(self.files[0],'rt')\n",
        "            handle1 = gzip.open(self.files[1],'rt')\n",
        "            # Associate label 0 with data from file 0. Same for 1.\n",
        "            for i in range(train_size):\n",
        "                row = next(handle0)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(0)\n",
        "                row = next(handle1)\n",
        "                self._load_line_(row)\n",
        "                self.labels.append(1)\n",
        "            handle0.close()\n",
        "            handle1.close()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print('Most likely, one file has too few reads.')\n",
        "            raise Exception('CANNOT LOAD DATA FROM FILE!')\n",
        "\n",
        "    def show_examples(self,head=6):\n",
        "        head = min(head,len(self.alignments))\n",
        "        for i in range(head):\n",
        "            print('From '+self.files[self.labels[i]])\n",
        "            print('Score,Edit,MM,HQMM,GapOpen,GapExtend,INS,DELS,HQINS,HQDEL')\n",
        "            print(self.alignments[i][0:9])\n",
        "            print(self.alignments[i][10:19])\n",
        "            print(self.alignments[i][20:29])\n",
        "            print(self.alignments[i][30:39])\n",
        "            print('Parent choice:',self.alignments[i][52])\n",
        "\n",
        "    def get_X_y(self):\n",
        "        loaded = len(self.alignments)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        X_train = np.array(self.alignments[:divider])\n",
        "        y_train = np.array(self.labels[:divider])\n",
        "        X_valid = np.array(self.alignments[divider:])\n",
        "        y_valid = np.array(self.labels[divider:])\n",
        "        if self.verbose:\n",
        "            print('Full train set size = '+str(len(self.alignments)))\n",
        "            print('Training/Validation partition: %d/%d'%(len(y_train),len(y_valid)))\n",
        "        return X_train,y_train, X_valid,y_valid\n",
        "\n",
        "    def get_predictions(self):\n",
        "        loaded = len(self.predictions)\n",
        "        divider = int(loaded - loaded * VALID_PORTION)\n",
        "        y_train = self.predictions[:divider]\n",
        "        y_valid = self.predictions[divider:]\n",
        "        return y_train, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcZVyvS_126",
        "outputId": "4b6a6de4-81d8-4f63-b297-72d0384e1316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-13 22:32:05.036149\n",
            "Maximum lines to load per file: 1000000\n",
            "LOADING\n",
            "Trying to load 1000000 lines per file...\n",
            "Number of ties: 67018\n",
            "2023-11-13 22:32:50.159786\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "filepath0 = DATA_DIR+DATA_FILE_0\n",
        "filepath1 = DATA_DIR+DATA_FILE_1\n",
        "loader=DataLoader(filepath0,filepath1)\n",
        "loader.set_max_lines(MAX_LINES_TO_LOAD)\n",
        "loader.set_num_features(len(feature_names))\n",
        "print('LOADING')\n",
        "loader.load_full_train_set()\n",
        "print('Number of ties: %d' % loader.count_ties())\n",
        "aligner_predictions_train, aligner_predictions_valid = loader.get_predictions()\n",
        "print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7uHn9Ib_129",
        "outputId": "133f9b7b-3ea1-4de8-a98e-dcdeabd4d394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full train set size = 2000000\n",
            "Training/Validation partition: 1600000/400000\n",
            "X train shape: \n",
            "(1600000, 53)\n",
            "y train shape: \n",
            "(1600000,)\n"
          ]
        }
      ],
      "source": [
        "X_train,y_train, X_valid,y_valid = loader.get_X_y()\n",
        "X_valid = None\n",
        "y_valid = None\n",
        "print('X train shape: ')\n",
        "print(np.shape(X_train))\n",
        "print('y train shape: ')\n",
        "print(np.shape(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZ6siB_Kq04"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AwMbRjm0FLBF"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    rfc = RFC()\n",
        "    return rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VCzbj21FMpfU"
      },
      "outputs": [],
      "source": [
        "# docs: Note that in binary classification, recall of the positive class is also known as “sensitivity”; recall of the negative class is “specificity”.\n",
        "def show_performance(y_valid, yhat_classes, yhat_pred):\n",
        "    accuracy = accuracy_score(y_valid, yhat_classes)*100.\n",
        "    precision = precision_score(y_valid, yhat_classes)*100.\n",
        "    recall = recall_score(y_valid, yhat_classes)*100.\n",
        "    sensitivity = recall_score(y_valid, yhat_classes, pos_label=1)*100.\n",
        "    specificity = recall_score(y_valid, yhat_classes, pos_label=0)*100.\n",
        "    f1 = f1_score(y_valid, yhat_classes)*100.\n",
        "    mcc = matthews_corrcoef(y_valid, yhat_classes)\n",
        "    if yhat_pred is None:\n",
        "        # these stats are possible for probabilistic models only\n",
        "        auprc = 0.\n",
        "        auroc = 0.\n",
        "    else:\n",
        "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_valid, yhat_pred)\n",
        "        auprc = auc(prc_X,prc_Y)*100.\n",
        "        auroc = roc_auc_score(y_valid, yhat_pred)*100.\n",
        "    values,counts=np.unique(yhat_classes, return_counts=True)\n",
        "    print('Predictions: ', dict(zip(values, counts)))\n",
        "    print('Accuracy: %.2f%% F1: %.2f%% MCC: %.4f' % (accuracy,f1,mcc))\n",
        "    print('Precision: %.2f%% Recall: %.2f%% AUPRC: %.2f%%' % (precision,recall,auprc))\n",
        "    print('Sensitivity: %.2f%% Specificity: %.2f%% AUROC: %.2f%%' % (sensitivity,specificity,auroc))\n",
        "    return accuracy,precision,recall,f1,sensitivity,specificity,mcc,auprc,auroc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfgplJ3Ep8Vr"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HCWG_w9_13F",
        "outputId": "4674705d-8d1f-4bdc-8ec0-91675519b812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-13 22:33:05.118991\n",
            "FOLD 1\n",
            "Training samples 1280000 Testing samples 320000\n",
            "Training...\n",
            "Elapsed seconds: 446.45025300979614\n",
            "Distrib of scores: 0.5009122201746447 mean 0.465624133084314 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[153294   6473]\n",
            " [  8086 152147]]\n",
            "Normalized matrix\n",
            " [[0.47904375 0.02022812]\n",
            " [0.02526875 0.47545938]]\n",
            "Predictions:  {0: 161380, 1: 158620}\n",
            "Accuracy: 95.45% F1: 95.43% MCC: 0.9091\n",
            "Precision: 95.92% Recall: 94.95% AUPRC: 99.06%\n",
            "Sensitivity: 94.95% Specificity: 95.95% AUROC: 99.01%\n",
            "2023-11-13 22:40:59.728340\n",
            "FOLD 2\n",
            "Training samples 1280000 Testing samples 320000\n",
            "Training...\n",
            "Elapsed seconds: 559.8821051120758\n",
            "Distrib of scores: 0.49927169194517657 mean 0.46548902267990044 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[153585   6553]\n",
            " [  8230 151632]]\n",
            "Normalized matrix\n",
            " [[0.47995312 0.02047812]\n",
            " [0.02571875 0.47385   ]]\n",
            "Predictions:  {0: 161815, 1: 158185}\n",
            "Accuracy: 95.38% F1: 95.35% MCC: 0.9077\n",
            "Precision: 95.86% Recall: 94.85% AUPRC: 99.02%\n",
            "Sensitivity: 94.85% Specificity: 95.91% AUROC: 98.99%\n",
            "2023-11-13 22:50:45.648752\n",
            "FOLD 3\n",
            "Training samples 1280000 Testing samples 320000\n",
            "Training...\n",
            "Elapsed seconds: 407.52570724487305\n",
            "Distrib of scores: 0.49927744153510867 mean 0.46555758533850944 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[153684   6439]\n",
            " [  8281 151596]]\n",
            "Normalized matrix\n",
            " [[0.4802625  0.02012188]\n",
            " [0.02587812 0.4737375 ]]\n",
            "Predictions:  {0: 161965, 1: 158035}\n",
            "Accuracy: 95.40% F1: 95.37% MCC: 0.9081\n",
            "Precision: 95.93% Recall: 94.82% AUPRC: 99.04%\n",
            "Sensitivity: 94.82% Specificity: 95.98% AUROC: 98.99%\n",
            "2023-11-13 22:57:58.301240\n",
            "FOLD 4\n",
            "Training samples 1280000 Testing samples 320000\n",
            "Training...\n",
            "Elapsed seconds: 620.1571638584137\n",
            "Distrib of scores: 0.4992869935173749 mean 0.4656451603059375 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[153655   6520]\n",
            " [  8303 151522]]\n",
            "Normalized matrix\n",
            " [[0.48017188 0.020375  ]\n",
            " [0.02594688 0.47350625]]\n",
            "Predictions:  {0: 161958, 1: 158042}\n",
            "Accuracy: 95.37% F1: 95.34% MCC: 0.9074\n",
            "Precision: 95.87% Recall: 94.80% AUPRC: 99.01%\n",
            "Sensitivity: 94.80% Specificity: 95.93% AUROC: 98.97%\n",
            "2023-11-13 23:08:44.077034\n",
            "FOLD 5\n",
            "Training samples 1280000 Testing samples 320000\n",
            "Training...\n",
            "Elapsed seconds: 1006.6128039360046\n",
            "Distrib of scores: 0.4997123162818727 mean 0.46569786867573226 std\n",
            "Range of scores: 0.0 to 1.0\n",
            "Confusion matrix\n",
            " [[153373   6424]\n",
            " [  8256 151947]]\n",
            "Normalized matrix\n",
            " [[0.47929063 0.020075  ]\n",
            " [0.0258     0.47483437]]\n",
            "Predictions:  {0: 161629, 1: 158371}\n",
            "Accuracy: 95.41% F1: 95.39% MCC: 0.9083\n",
            "Precision: 95.94% Recall: 94.85% AUPRC: 99.04%\n",
            "Sensitivity: 94.85% Specificity: 95.98% AUROC: 99.00%\n",
            "2023-11-13 23:25:54.917229\n"
          ]
        }
      ],
      "source": [
        "print(datetime.now())\n",
        "FOLD = 0\n",
        "accuracyCV=list()\n",
        "precisionCV=list()\n",
        "recallCV=list()\n",
        "f1CV=list()\n",
        "sensitivityCV=list()\n",
        "specificityCV=list()\n",
        "mccCV=list()\n",
        "auprcCV=list()\n",
        "aurocCV=list()\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, test_index in kfold.split(X_train, y_train):\n",
        "    rfc_model=build_model()\n",
        "    FOLD += 1\n",
        "    print('FOLD', FOLD)\n",
        "    print('Training samples', len(train_index), 'Testing samples', len(test_index) )\n",
        "    print('Training...')\n",
        "    start_time = time.time()\n",
        "    rfc_model.fit(X_train[train_index], y_train[train_index])\n",
        "    end_time = time.time()\n",
        "    print('Elapsed seconds:', (end_time-start_time))\n",
        "\n",
        "    yhat_pairs=rfc_model.predict_proba(X_train[test_index])\n",
        "    yhat_pred=[pair[1] for pair in yhat_pairs]\n",
        "    yhat_classes=rfc_model.predict(X_train[test_index])\n",
        "\n",
        "    print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
        "    print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
        "    cm1 = confusion_matrix(y_train[test_index],yhat_classes)\n",
        "    print('Confusion matrix\\n',cm1)\n",
        "    cm2 = confusion_matrix(y_train[test_index],yhat_classes,normalize='all')\n",
        "    print('Normalized matrix\\n',cm2)\n",
        "\n",
        "    accuracy,precision,recall,f1,sensitivity,specificity,mcc,auprc,auroc=\\\n",
        "        show_performance(y_train[test_index], yhat_classes, yhat_pred)\n",
        "    accuracyCV.append   (accuracy)\n",
        "    precisionCV.append  (precision)\n",
        "    recallCV.append     (recall)\n",
        "    f1CV.append         (f1)\n",
        "    sensitivityCV.append(sensitivity)\n",
        "    specificityCV.append(specificity)\n",
        "    mccCV.append        (mcc)\n",
        "    auprcCV.append      (auprc)\n",
        "    aurocCV.append      (auroc)\n",
        "    print(datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8QbOpY_13G",
        "outputId": "d65dd04e-9fe5-4eb5-c47b-8b8c944ecfb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy    95.4021875 0.028591273799883146\n",
            "precision   95.90407247531998 0.03260417225411011\n",
            "recall      94.85545660909295 0.05197269639652894\n",
            "f1          95.3768746168046 0.03396550442791923\n",
            "sensitivity 94.85545660909295 0.05197269639652894\n",
            "specificity 95.94888948401594 0.02796075589436745\n",
            "mcc         0.9080980368728842 0.00057051634708515\n",
            "auprc       99.03274449241738 0.01549315995771205\n",
            "auroc       98.99131009309215 0.013279607797695998\n"
          ]
        }
      ],
      "source": [
        "print('accuracy   ',   np.mean(accuracyCV),    np.std(accuracyCV))\n",
        "print('precision  ',  np.mean(precisionCV),   np.std(precisionCV))\n",
        "print('recall     ',     np.mean(recallCV),      np.std(recallCV))\n",
        "print('f1         ',         np.mean(f1CV),          np.std(f1CV))\n",
        "print('sensitivity',np.mean(sensitivityCV), np.std(sensitivityCV))\n",
        "print('specificity',np.mean(specificityCV), np.std(specificityCV))\n",
        "print('mcc        ',        np.mean(mccCV),         np.std(mccCV))\n",
        "print('auprc      ',      np.mean(auprcCV),       np.std(auprcCV))\n",
        "print('auroc      ',      np.mean(aurocCV),       np.std(aurocCV))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}